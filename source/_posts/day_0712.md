## 프로젝트 개요 

- 강의명 : 2022년 K-디지털 직업훈련(Training) 사업 - AI데이터플랫폼을 활용한 빅데이터 분석전문가 과정
- 교과목명 : 빅데이터 분석 및 시각화, AI개발 기초, 인공지능 프로그래밍
- 프로젝트 주제 : 캐글 대회 Bike Sharing Demand 데이터를 활용한 수요 예측 대회
- 프로젝트 마감일 : 2022년 7월 19일 화요일
- 수강생명 : 박근태


```python
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
```


```python
"""필요 라이브러리들 호출"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np 
import pandas as pd 
import seaborn as sns #시각화를 위한 라이브러리
import matplotlib.pyplot as plt
import calendar 
from datetime import datetime

import os
print(os.listdir("../input"))

```


```python
"""
train_data의 season(계절)값이 1월에 봄으로 설정 되어있다. 네이버에 검색 해보니 3월~5월이 봄이다.
따라서 badToRight를 이용하여 season column을 수정하였다.
"""
def badToRight(month):
    if month in [12,1,2]:
        return 4
    elif month in [3,4,5]:
        return 1
    elif month in [6,7,8]:
        return 2
    elif month in [9,10,11]:
        return 3
```


```python
train_data = pd.read_csv("/kaggle/input/bike-sharing-demand/train.csv")
test_data = pd.read_csv("/kaggle/input/bike-sharing-demand/test.csv")
submission = pd.read_csv("/kaggle/input/bike-sharing-demand/sampleSubmission.csv")
```


```python
# 훈련, 테스트 데이터셋의 형태 및 컬럽의 속성 테이터 값 파악
train_data.head()
```


```python
test_data.head()
```


```python
# 데이터 전처리 및 시각과 (그 이유는 어떻게 생겼는지 확인을 위해)
train_data['tempDate'] = train_data.datetime.apply(lambda x:x.split())
```


```python
train_data['year'] = train_data.tempDate.apply(lambda x:x[0].split('-')[0])
train_data['month'] = train_data.tempDate.apply(lambda x:x[0].split('-')[1])
train_data['day'] = train_data.tempDate.apply(lambda x:x[0].split('-')[2])
train_data['hour'] = train_data.tempDate.apply(lambda x:x[1].split(':')[0])
```


```python
train_data['weekday'] = train_data.tempDate.apply(lambda x:calendar.day_name[datetime.strptime(x[0],"%Y-%m-%d").weekday()])
```


```python
train_data['year'] = pd.to_numeric(train_data.year,errors='coerce')
train_data['month'] = pd.to_numeric(train_data.month,errors='coerce')
train_data['day'] = pd.to_numeric(train_data.day,errors='coerce')
train_data['hour'] = pd.to_numeric(train_data.hour,errors='coerce')
```


```python
train_data.info()
```


```python
train_data = train_data.drop('tempDate', axis=1)

```


```python
# count 와 다른값들의 상관관계

fig = plt.figure(figsize=[15,12])

# 년도와의 관계
ax1 = fig.add_subplot(2,2,1)
ax1 = sns.barplot(x='year',y='count', data=train_data.groupby('year')['count'].mean().reset_index())

# 달과의 관계
ax2 = fig.add_subplot(2,2,2)
ax2 = sns.barplot(x='month',y='count',data=train_data.groupby('month')['count'].mean().reset_index())

# 날짜와의 관계
ax3 = fig.add_subplot(2,2,3)
ax3 = sns.barplot(x='day',y='count',data=train_data.groupby('day')['count'].mean().reset_index())

# 시간과의 관계
ax4 = fig.add_subplot(2,2,4)
ax4 = sns.barplot(x='hour',y='count',data=train_data.groupby('hour')['count'].mean().reset_index())
```


![png](/images/Kaggle_0712/output_12_1.png)
h

```python
#계절과 관계
fig = plt.figure(figsize=[15,12])
ax1 = fig.add_subplot(2,2,1)
ax1 = sns.barplot(x='season',y='count',data=train_data.groupby('season')['count'].mean().reset_index())

#휴일 여부와의 관계
ax2 = fig.add_subplot(2,2,2)
ax2 = sns.barplot(x='holiday',y='count',data=train_data.groupby('holiday')['count'].mean().reset_index())

#작업일 여부와의 관계
ax3 = fig.add_subplot(2,2,3)
ax3 = sns.barplot(x='workingday',y='count',data=train_data.groupby('workingday')['count'].mean().reset_index())

#날씨와의 관계 
ax4 = fig.add_subplot(2,2,4)
ax4 = sns.barplot(x='weather',y='count',data=train_data.groupby('weather')['count'].mean().reset_index())
```


![png](/images/Kaggle_0712/output_12_2.png)


```python
train_data.head(5)
```


```python
train_data['season'] = train_data.month.apply(badToRight)
```


```python
train_data.head(5)
```


```python
#계절과 관계
fig = plt.figure(figsize=[15,12])
ax1 = fig.add_subplot(2,2,1)
ax1 = sns.barplot(x='season',y='count',data=train_data.groupby('season')['count'].mean().reset_index())

#휴일 여부와의 관계
ax2 = fig.add_subplot(2,2,2)
ax2 = sns.barplot(x='holiday',y='count',data=train_data.groupby('holiday')['count'].mean().reset_index())

#작업일 여부와의 관계
ax3 = fig.add_subplot(2,2,3)
ax3 = sns.barplot(x='workingday',y='count',data=train_data.groupby('workingday')['count'].mean().reset_index())

#날씨와의 관계 
ax4 = fig.add_subplot(2,2,4)
ax4 = sns.barplot(x='weather',y='count',data=train_data.groupby('weather')['count'].mean().reset_index())
```


![png](/images/Kaggle_0712/output_12_3.png)


```python
#남은 분포를 통해 표현하였을 때 좋은 컬럼들을 count와 비교

#온도와 count
fig = plt.figure(figsize=[12,10])
ax1 = fig.add_subplot(2,2,1)
ax1 = sns.distplot(train_data.temp,bins=range(train_data.temp.min().astype('int'),train_data.temp.max().astype('int')+1))

#평균온도와 count
ax2 = fig.add_subplot(2,2,2)
ax2 = sns.distplot(train_data.atemp,bins=range(train_data.atemp.min().astype('int'),train_data.atemp.max().astype('int')+1))

#습도와 count
ax3 = fig.add_subplot(2,2,3)
ax3 = sns.distplot(train_data.humidity,bins=range(train_data.humidity.min().astype('int'),train_data.humidity.max().astype('int')+1))

#바람속도와 count
ax4 = fig.add_subplot(2,2,4)
ax4 = sns.distplot(train_data.windspeed,bins=range(train_data.windspeed.min().astype('int'),train_data.windspeed.max().astype('int')+1))
```


![png](/images/Kaggle_0712/output_12_4.png)


```python
fig = plt.figure(figsize=[20,20])
ax = sns.heatmap(train_data.corr(),annot=True,square=True)
```


![png](/images/Kaggle_0712/output_12_5.png)


```python
#heatmap 상관관계를 참조하여 이전의 시각화와는 달리 두 개의 서로다른 컬럼이 적용된 count를 시각화해보자

#시간과 계절에 따른 count
fig = plt.figure(figsize=[12,10])
ax1 = fig.add_subplot(2,2,1)
ax1 = sns.pointplot(x='hour',y='count',hue='season',data=train_data.groupby(['season','hour'])['count'].mean().reset_index())

#시간과 휴일 여부에 따른 count
ax2 = fig.add_subplot(2,2,2)
ax2 = sns.pointplot(x='hour',y='count',hue='holiday',data=train_data.groupby(['holiday','hour'])['count'].mean().reset_index())

#시간과 평일 여부에 따른 count
ax3 = fig.add_subplot(2,2,3)
ax3 = sns.pointplot(x='hour',y='count',hue='weekday',hue_order=['Sunday','Monday','Tuesday','Wendnesday','Thursday','Friday','Saturday'],data=train_data.groupby(['weekday','hour'])['count'].mean().reset_index())

#시간과 날씨에 따른 count
ax4 = fig.add_subplot(2,2,4)
ax4 = sns.pointplot(x='hour',y='count',hue='weather',data=train_data.groupby(['weather','hour'])['count'].mean().reset_index())
```


![png](/images/Kaggle_0712/output_12_6.png)


```python
#마지막 시각화에 이상치가 있는 것같아서 확인

train_data[train_data.weather==4]
```


```python
#달과 날씨에 따른 count 
fig = plt.figure(figsize=[12,10])
ax1 = fig.add_subplot(2,1,1)
ax1 = sns.pointplot(x='month',y='count',hue='weather',data=train_data.groupby(['weather','month'])['count'].mean().reset_index())

#달별 count
ax2 = fig.add_subplot(2,1,2)
ax2 = sns.barplot(x='month',y='count',data=train_data.groupby('month')['count'].mean().reset_index())
```


![png](/images/Kaggle_0712/output_12_7.png)


```python
"""
Windspeed 분포를 표현한 그래프에서 Windspeed가 0인 값들이 많았는데,
이는 실제로 0이었던지 or 값을 제대로 측정하지 못해서 0인지 두 개의 경우가 있다.
하지만 후자의 생각을 가지고 우리의 데이터를 활용하여 windspeed값을 부여해보자
"""

#머신러닝 모델에 훈련시킬 때는 문자열 값은 불가능하기 때문에 문자열을 카테고리화 하고 각각에 해당하는 값을 숫자로 변환해준다
train_data['weekday']= train_data.weekday.astype('category')
```


```python
print(train_data['weekday'].cat.categories)
```


```python
#0:Sunday --> 6:Saturday
train_data.weekday.cat.categories = ['5','1','6','0','4','2','3']
```


```python
"""
RandomForest를 활용하여 Windspeed값을 부여해보자
하나의 데이터를 Windspeed가 0인 그리고 0이 아닌 데이터프레임으로 분리하고
학습시킬 0이 아닌 데이터 프레임에서는 Windspeed만 담긴 Series와 이외의 학습시킬 column들의 데이터프레임으로 분리한다
학습 시킨 후에 Windspeed가 0인 데이터 프레임에서 학습시킨 컬럼과 같게 추출하여 결과 값을 부여받은 후,
Windspeed가 0인 데이터프레임에 Windspeed값을 부여한다.
"""
from sklearn.ensemble import RandomForestRegressor

#Windspeed가 0인 데이터프레임
windspeed_0 = train_data[train_data.windspeed == 0]

#Windspeed가 0이 아닌 데이터프레임
windspeed_Not0 = train_data[train_data.windspeed != 0]

#Windspeed가 0인 데이터 프레임에 투입을 원치 않는 컬럼을 배제
windspeed_0_df = windspeed_0.drop(['windspeed','casual','registered','count','datetime'],axis=1)

#Windspeed가 0이 아닌 데이터 프레임은 위와 동일한 데이터프레임을 형성하고 학습시킬 Windspeed Series를 그대로 둠
windspeed_Not0_df = windspeed_Not0.drop(['windspeed','casual','registered','count','datetime'],axis=1)
windspeed_Not0_series = windspeed_Not0['windspeed'] 

#모델에 0이 아닌 데이터프레임과 결과값을 학습
rf = RandomForestRegressor()
rf.fit(windspeed_Not0_df,windspeed_Not0_series)

#학습된 모델에 Windspeed가 0인 데이터프레임의 Windspeed를 도출
predicted_windspeed_0 = rf.predict(windspeed_0_df)

#도출된 값을 원래의 데이터프레임에 삽입
windspeed_0['windspeed'] = predicted_windspeed_0
```


```python
#나눈 데이터 프레임을 원래의 형태로 복원
train_data = pd.concat([windspeed_0,windspeed_Not0],axis=0)
```


```python
#시간별 정렬을 위해 string type의 datetime을 datetime으로 변환
train_data.datetime = pd.to_datetime(train_data.datetime,errors='coerce')
```


```python
#windspeed를 수정한 후 다시 상관계수를 분석
#우리의 기대와는 달리 windspeed와 count의 상관관계는 0.1에서 0.11로 간소한 차이만 보임.
fig = plt.figure(figsize=[20,20])
ax = sns.heatmap(train_data.corr(),annot=True,square=True)
```


![png](/images/Kaggle_0712/output_12_8.png)


```python
fig = plt.figure(figsize=[5,5])
sns.distplot(train_data['windspeed'],bins=np.linspace(train_data['windspeed'].min(),train_data['windspeed'].max(),10))
plt.suptitle("Filled by Random Forest Regressor")
print("Min value of windspeed is {}".format(train_data['windspeed'].min()))
```


![png](/images/Kaggle_0712/output_12_9.png)


```python
test_data.info()
```


```python
test_data['tempDate'] = test_data.datetime.apply(lambda x:x.split())
test_data['weekday'] = test_data.tempDate.apply(lambda x: calendar.day_name[datetime.strptime(x[0],"%Y-%m-%d").weekday()])
test_data['year'] = test_data.tempDate.apply(lambda x: x[0].split('-')[0])
test_data['month'] = test_data.tempDate.apply(lambda x: x[0].split('-')[1])
test_data['day'] = test_data.tempDate.apply(lambda x: x[0].split('-')[2])
test_data['hour'] = test_data.tempDate.apply(lambda x: x[1].split(':')[0])
```


```python
test_data['year'] = pd.to_numeric(test_data.year,errors='coerce')
test_data['month'] = pd.to_numeric(test_data.month,errors='coerce')
test_data['day'] = pd.to_numeric(test_data.day,errors='coerce')
test_data['hour'] = pd.to_numeric(test_data.hour,errors='coerce')
```


```python
test_data.info()
```


```python
test_data['season'] = test_data.month.apply(badToRight)
```


```python
test_data.head()
```


```python
test_data.weekday = test_data.weekday.astype('category')
```


```python
test_data.weekday
```


```python
test_data.weekday.cat.categories = ['5','1','6','0','4','2','3']
```


```python
dataWind0 = test_data[test_data['windspeed']==0]
dataWindNot0 = test_data[test_data['windspeed']!=0]
```


```python
dataWind0.columns
```


```python
dataWind0_df = dataWind0.drop(['windspeed','datetime','tempDate'],axis=1)

dataWindNot0_df = dataWindNot0.drop(['windspeed','datetime','tempDate'],axis=1)

dataWindNot0_series = dataWindNot0['windspeed']
```


```python
dataWindNot0_df.head()
```


```python
dataWind0_df.head()
```


```python
rf2 = RandomForestRegressor()
rf2.fit(dataWindNot0_df,dataWindNot0_series)
predicted = rf2.predict(dataWind0_df)
print(predicted)
```


```python
dataWind0['windspeed'] = predicted
```


```python
test_data = pd.concat([dataWind0,dataWindNot0],axis=0)
```


```python
train_data = pd.concat([windspeed_0,windspeed_Not0],axis=0)
```


```python
combine = pd.concat([test_data,train_data],axis=0)
```


```python
# column들 중 값들이 일정하고 정해져있다면 category로 변경하고 필요하지 않은 column들은 이제 버린다.
categorizational_columns = ['holiday','humidity','season','weather','workingday','year','month','day','hour']
drop_columns = ['datetime','casual','registered','count','tempDate']
```


```python
for col in categorizational_columns:
    combine[col] = combine[col].astype('category')
```


```python
#합친 combine데이터 셋에서 count의 유무로 훈련과 테스트셋을 분리하고 각각을 datetime으로 정렬

train = combine[pd.notnull(combine['count'])].sort_values(by='datetime')
test = combine[~pd.notnull(combine['count'])].sort_values(by='datetime')
```


```python
#데이터 훈련시 집어 넣게 될 각각의 결과 값들

datetimecol = test['datetime']
yLabels = train['count'] #count
yLabelsRegistered = train['registered'] #등록된 사용자
yLabelsCasual = train['casual'] #임시 사용자
```


```python
# 필요 없는 column들을 버리고 훈련과 테스트 셋을 한다.
train = train.drop(drop_columns,axis=1)
test = test.drop(drop_columns,axis=1)
```


```python
def rmsle(y, y_,convertExp=True):
    if convertExp:
        y = np.exp(y), 
        y_ = np.exp(y_)
    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))
    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))
    calc = (log1 - log2) ** 2
    return np.sqrt(np.mean(calc))
```


```python
from sklearn.linear_model import LinearRegression,Ridge,Lasso


lr = LinearRegression()

yLabelslog = np.log1p(yLabels)
#선형 모델에 우리의 데이터를 학습
lr.fit(train,yLabelslog)
#결과 값 도출
preds = lr.predict(train)

print('RMSLE Value For Linear Regression: {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))
```


```python
#count값의 분포
sns.distplot(yLabels,bins=range(yLabels.min().astype('int'),yLabels.max().astype('int')))

#기존 훈련 데이터셋의 count의 개수
print(yLabels.count()) #10886

#3시그마를 적용한 이상치를 배제한 훈련 데이터셋의 count의 개수
yLabels[np.logical_and(yLabels.mean()-3*yLabels.std() <= yLabels,yLabels.mean()+3*yLabels.std() >= yLabels)].count() #10739
#이상치들이 존재할 때는 log를 활용하여 값을 도출
```


![png](/images/Kaggle_0712/output_12_10.png)


```python
from sklearn.model_selection import GridSearchCV
from sklearn import metrics

#Ridge모델은 L2제약을 가지는 선형회귀모델에서 개선된 모델이며 해당 모델에서 유의 깊게 튜닝해야하는 파라미터는 alpha값이다.
ridge = Ridge()

#튜닝하고자하는 Ridge의 파라미터 중 특정 파라미터에 배열 값으로 넘겨주게 되면 테스트 후 어떤 파라미터가 최적의 값인지 알려줌 
ridge_params = {'max_iter':[3000],'alpha':[0.001,0.01,0.1,1,10,100,1000]}
rmsle_scorer = metrics.make_scorer(rmsle,greater_is_better=False)
grid_ridge = GridSearchCV(ridge,ridge_params,scoring=rmsle_scorer,cv=5)

grid_ridge.fit(train,yLabelslog)
preds = grid_ridge.predict(train)
print(grid_ridge.best_params_)
print('RMSLE Value for Ridge Regression {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))
```


```python
#결과에 대해 GridSearchCV의 변수인 grid_ridge변수에 cv_result_를 통해 alpha값의 변화에 따라 평균값의 변화를 파악 가능
df = pd.DataFrame(grid_ridge.cv_results_)
```


```python
df.head()
```


```python
#Ridge모델은 L1제약을 가지는 선형회귀모델에서 개선된 모델이며 해당 모델에서 유의 깊게 튜닝해야하는 파라미터는 alpha값이다.
lasso = Lasso()

lasso_params = {'max_iter':[3000],'alpha':[0.001,0.01,0.1,1,10,100,1000]}
grid_lasso = GridSearchCV(lasso,lasso_params,scoring=rmsle_scorer,cv=5)
grid_lasso.fit(train,yLabelslog)
preds = grid_lasso.predict(train)
print('RMSLE Value for Lasso Regression {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))
```


```python
rf = RandomForestRegressor()

rf_params = {'n_estimators':[1,10,100]}
grid_rf = GridSearchCV(rf,rf_params,scoring=rmsle_scorer,cv=5)
grid_rf.fit(train,yLabelslog)
preds = grid_rf.predict(train)
print('RMSLE Value for RandomForest {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))
```


```python
from sklearn.ensemble import GradientBoostingRegressor

gb = GradientBoostingRegressor()
gb_params={'max_depth':range(1,11,1),'n_estimators':[1,10,100]}
grid_gb=GridSearchCV(gb,gb_params,scoring=rmsle_scorer,cv=5)
grid_gb.fit(train,yLabelslog)
preds = grid_gb.predict(train)
print('RMSLE Value for GradientBoosting {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))
```


```python
predsTest = grid_gb.predict(test)
fig,(ax1,ax2)= plt.subplots(ncols=2)
fig.set_size_inches(12,5)
sns.distplot(yLabels,ax=ax1,bins=50)
sns.distplot(np.exp(predsTest),ax=ax2,bins=50)
```

![png](/images/Kaggle_0712/output_12_11.png)


```python
submission = pd.DataFrame({
        "datetime": datetimecol,
        "count": [max(0, x) for x in np.exp(predsTest)]
    })
submission.to_csv('bike_predictions_gbm_separate_without_fe.csv', index=False)
```


```python
submission.head()
```
